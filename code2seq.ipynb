{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code2seq.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m3yrin/code2seq/blob/master/code2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5OLd1AL5gIQw"
      },
      "cell_type": "markdown",
      "source": [
        "# A PyTorch re-implementation code for \"code2seq: Generating Sequences from Structured Representations of Code\"\n",
        "\n",
        "* Paper(Arxiv) : https://arxiv.org/abs/1808.01400  \n",
        "* Official Github : https://github.com/tech-srl/code2seq\n",
        "\n",
        "Apr 30, 2019 : v3"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AuNCHQZ4RR8R",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load dataset before run.\n",
        "!wget https://s3.amazonaws.com/code2seq/datasets/java-small-preprocessed.tar.gz\n",
        "!tar -xvzf java-small-preprocessed.tar.gz\n",
        "!ls java-small"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cnth1kMQwrNl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import pickle\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from nltk import bleu_score\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import einsum\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "random_state = 42\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Hb3ecdDlwrNr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Vocab(object):\n",
        "    def __init__(self, word2id={}):\n",
        "        \"\"\"\n",
        "        word2id: dict str to int\n",
        "        id2word: dict int to str\n",
        "        \"\"\"\n",
        "        self.word2id = dict(word2id)\n",
        "        self.id2word = {v: k for k, v in self.word2id.items()}    \n",
        "        \n",
        "    def build_vocab(self, sentences, min_count=1):\n",
        "        # counting population of each word\n",
        "        word_counter = {}\n",
        "        for word in sentences:\n",
        "            word_counter[word] = word_counter.get(word, 0) + 1\n",
        "\n",
        "        # use only the words that  word_count > min_count\n",
        "        for word, count in sorted(word_counter.items(), key=lambda x: -x[1]):\n",
        "            if count < min_count:\n",
        "                break\n",
        "            _id = len(self.word2id)\n",
        "            self.word2id.setdefault(word, _id)\n",
        "            self.id2word[_id] = word "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JM84CUHawrNv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PAD_TOKEN = '<PAD>' \n",
        "BOS_TOKEN = '<S>' \n",
        "EOS_TOKEN = '</S>'\n",
        "UNK_TOKEN = '<UNK>'\n",
        "PAD = 0\n",
        "BOS = 1\n",
        "EOS = 2\n",
        "UNK = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mjRMDX0gwrNy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load vocab dict\n",
        "with open('java-small/java-small.dict.c2s', 'rb') as file:\n",
        "    subtoken_to_count = pickle.load(file)\n",
        "    node_to_count = pickle.load(file) \n",
        "    target_to_count = pickle.load(file)\n",
        "    max_contexts = pickle.load(file)\n",
        "    num_training_examples = pickle.load(file)\n",
        "    print('Dictionaries loaded.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bRqsluoYwrOC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# making vocab dicts for terminal subtoken, nonterminal node and target.\n",
        "\n",
        "word2id = {\n",
        "    PAD_TOKEN: PAD,\n",
        "    BOS_TOKEN: BOS,\n",
        "    EOS_TOKEN: EOS,\n",
        "    UNK_TOKEN: UNK,\n",
        "    }\n",
        "\n",
        "vocab_subtoken = Vocab(word2id=word2id)\n",
        "vocab_nodes = Vocab(word2id=word2id)\n",
        "vocab_target = Vocab(word2id=word2id)\n",
        "\n",
        "\n",
        "vocab_subtoken.build_vocab(list(subtoken_to_count.keys()), min_count=0)\n",
        "vocab_nodes.build_vocab(list(node_to_count.keys()), min_count=0)\n",
        "vocab_target.build_vocab(list(target_to_count.keys()), min_count=0)\n",
        "\n",
        "vocab_size_subtoken = len(vocab_subtoken.id2word)\n",
        "vocab_size_nodes = len(vocab_nodes.id2word)\n",
        "vocab_size_target = len(vocab_target.id2word)\n",
        "\n",
        "print('vocab_size_subtoken：', vocab_size_subtoken)\n",
        "print('vocab_size_nodes：', vocab_size_nodes)\n",
        "print('vocab_size_target：', vocab_size_target)\n",
        "\n",
        "num_length_train = num_training_examples\n",
        "print('num_examples : ', num_length_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zW4LTL_GQu7i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sentence_to_ids(vocab, sentence):\n",
        "    # translate word to id\n",
        "    ids = [vocab.word2id.get(word, UNK) for word in sentence]\n",
        "    ids += [EOS]  # adding EOS to the end of sentence\n",
        "    return ids\n",
        "  \n",
        "  \n",
        "def pad_seq(seq, max_length):\n",
        "    # pad tail of sequence to extend sequence length up to max_length\n",
        "    res = seq + [PAD for i in range(max_length - len(seq))]\n",
        "    return res \n",
        "\n",
        "def ids_to_sentence(vocab, ids):\n",
        "    return [vocab.id2word[_id] for _id in ids]\n",
        "\n",
        "def trim_eos(ids):\n",
        "    # trim tokens after eos\n",
        "    if EOS in ids:\n",
        "        return ids[:ids.index(EOS)]\n",
        "    else:\n",
        "        return ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FsKqxYglB4Vw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DataLoader(object):\n",
        "\n",
        "    def __init__(self, data_path, num_examples, batch_size, num_k, vocab_subtoken, vocab_nodes, vocab_target, sector_size = 1):\n",
        "        \n",
        "        \"\"\"\n",
        "        data_path : path for data \n",
        "        num_examples : total lines of data file\n",
        "        batch_size : batch size\n",
        "        num_k : max ast pathes included to one examples\n",
        "        vocab_subtoken : dict of subtoken and its id\n",
        "        vocab_nodes : dict of node simbol and its id\n",
        "        vocab_target : dict of target simbol and its id\n",
        "        sector_size : data/sector_size is stored on memory. if you have enough RAM, sector_size = 1. For Google Coraboratory, sector_size = 10.\n",
        "        \"\"\"\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        self.start_index = 0\n",
        "        self.num_examples = num_examples\n",
        "        self.num_k = num_k\n",
        "        self.data_path = data_path\n",
        "        \n",
        "        self.vocab_subtoken = vocab_subtoken\n",
        "        self.vocab_nodes = vocab_nodes\n",
        "        self.vocab_target = vocab_target\n",
        "        \n",
        "        self.sector_size = sector_size\n",
        "        self.sector = 0\n",
        "        \n",
        "        print('Sector size :', sector_size)\n",
        "        print(self.num_examples//self.sector_size//self.batch_size, 'iter / sector')\n",
        "        \n",
        "        self.reset()\n",
        "\n",
        "    \n",
        "    def reset(self):\n",
        "        self.data = self.data_sampler()\n",
        "        self.start_index = 0 \n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "      \n",
        "        if self.start_index >= self.num_examples//self.sector_size:\n",
        "            print('Sector', self.sector + 1, ' / ', self.sector_size, ' done.')\n",
        "            self.sector += 1\n",
        "            \n",
        "            if self.sector >= self.sector_size:\n",
        "                self.sector = 0\n",
        "                self.reset()\n",
        "                raise StopIteration()\n",
        "            \n",
        "            self.reset()\n",
        "            \n",
        "        seqs_S, seqs_N, seqs_E, seqs_Y = self.data\n",
        "        \n",
        "        batch_seqs_S = seqs_S[self.start_index: self.start_index + self.batch_size]\n",
        "        batch_seqs_N = seqs_N[self.start_index: self.start_index + self.batch_size]\n",
        "        batch_seqs_E = seqs_E[self.start_index: self.start_index + self.batch_size]\n",
        "        batch_seqs_Y = seqs_Y[self.start_index: self.start_index + self.batch_size]\n",
        "        \n",
        "        # length_k : (batch_size, k)\n",
        "        lengths_k = [len(ex) for ex in batch_seqs_N]\n",
        "        \n",
        "        #\n",
        "        # flattening (batch_size, k, l) to (batch_size * k, l)\n",
        "        # this is useful to make torch.tensor\n",
        "        \n",
        "        batch_seqs_S = [symbol for k in batch_seqs_S for symbol in k]\n",
        "        batch_seqs_N = [symbol for k in batch_seqs_N for symbol in k] \n",
        "        batch_seqs_E = [symbol for k in batch_seqs_E for symbol in k] \n",
        "        \n",
        "        #\n",
        "        # Padding\n",
        "        #\n",
        "        \n",
        "        lengths_S = [len(s) for s in batch_seqs_S]\n",
        "        lengths_N = [len(s) for s in batch_seqs_N]\n",
        "        lengths_E = [len(s) for s in batch_seqs_E]\n",
        "        lengths_Y = [len(s) for s in batch_seqs_Y]\n",
        "        \n",
        "        max_length_S = max(lengths_S)\n",
        "        max_length_N = max(lengths_N)\n",
        "        max_length_E = max(lengths_E)\n",
        "        max_length_Y = max(lengths_Y)\n",
        "\n",
        "        padded_S = [pad_seq(s, max_length_S) for s in batch_seqs_S]\n",
        "        padded_N = [pad_seq(s, max_length_N) for s in batch_seqs_N]\n",
        "        padded_E = [pad_seq(s, max_length_E) for s in batch_seqs_E]\n",
        "        padded_Y = [pad_seq(s, max_length_Y) for s in batch_seqs_Y]\n",
        "        \n",
        "        # index for split (batch_size * k, l) into (batch_size, k, l)\n",
        "        index_N = range(len(lengths_N))\n",
        "        \n",
        "        \n",
        "        # sort for rnn\n",
        "        seq_pairs = sorted(zip(lengths_N, index_N, padded_N, padded_S, padded_E), key=lambda p: p[0], reverse=True)\n",
        "        lengths_N, index_N, padded_N, padded_S, padded_E = zip(*seq_pairs)\n",
        "        \n",
        "        batch_S = torch.tensor(padded_S, dtype=torch.long, device=device)\n",
        "        batch_E = torch.tensor(padded_E, dtype=torch.long, device=device)\n",
        "        \n",
        "        # transpose for rnn\n",
        "        batch_N = torch.tensor(padded_N, dtype=torch.long, device=device).transpose(0, 1)\n",
        "        batch_Y = torch.tensor(padded_Y, dtype=torch.long, device=device).transpose(0, 1)\n",
        "        \n",
        "        # update index\n",
        "        self.start_index += self.batch_size\n",
        "\n",
        "        return batch_S, batch_N, batch_E, batch_Y, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N\n",
        "    \n",
        "    def data_sampler(self):\n",
        "        \n",
        "        seqs_S = []\n",
        "        seqs_E = []\n",
        "        seqs_N = []\n",
        "        seqs_Y = []\n",
        "        \n",
        "        \n",
        "        with open(self.data_path, 'r') as f:\n",
        "          \n",
        "            for i, line in enumerate(f) :\n",
        "                \n",
        "                if ( i < self.num_examples // self.sector_size * self.sector):\n",
        "                  continue\n",
        "                \n",
        "                if (i >= self.num_examples // self.sector_size * (self.sector + 1)):\n",
        "                    break\n",
        "                \n",
        "                \n",
        "                seq_S = []\n",
        "                seq_N = []\n",
        "                seq_E = []\n",
        "                \n",
        "                target, *syntax_path = line.split(' ')\n",
        "                target = target.split('|')\n",
        "                target =  sentence_to_ids(self.vocab_target, target)\n",
        "                \n",
        "                # remove '' and '\\n' in sequence, java-small dataset contains many '' in a line.\n",
        "                syntax_path = [s for s in syntax_path if s != '' and s != '\\n']\n",
        "\n",
        "                # if the amount of ast path exceed the k, uniformly sample ast pathes, as described in the paper.\n",
        "                if len(syntax_path) > self.num_k:\n",
        "                    sampled_path_index = random.sample(range(len(syntax_path)) , self.num_k)\n",
        "                else :\n",
        "                    sampled_path_index = range(len(syntax_path))\n",
        "                \n",
        "                \n",
        "                for j in sampled_path_index:\n",
        "                    terminal1, ast_path, terminal2 = syntax_path[j].split(',')\n",
        "\n",
        "                    terminal1 = sentence_to_ids(self.vocab_subtoken, terminal1.split('|'))\n",
        "                    ast_path = sentence_to_ids(self.vocab_nodes, ast_path.split('|'))\n",
        "                    terminal2 = sentence_to_ids(self.vocab_subtoken, terminal2.split('|')) \n",
        "\n",
        "                    seq_S.append(terminal1)\n",
        "                    seq_E.append(terminal2)\n",
        "                    seq_N.append(ast_path)\n",
        "                \n",
        "                seqs_S.append(seq_S)\n",
        "                seqs_E.append(seq_E)\n",
        "                seqs_N.append(seq_N)\n",
        "                seqs_Y.append(target)\n",
        "\n",
        "        return seqs_S, seqs_N, seqs_E, seqs_Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-7lLgR9WwrPS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size_subtoken, input_size_node, token_size, hidden_size, rnn_dropout = 0.5, embeddings_dropout = 0.25):\n",
        "        \n",
        "        \"\"\"\n",
        "        input_size_subtoken : # of unique subtoken\n",
        "        input_size_node : # of unique node symbol\n",
        "        token_size : embedded token size\n",
        "        hidden_size : size of initial state of decoder\n",
        "        rnn_dropout = 0.5 : rnn drop out ratio\n",
        "        embeddings_dropout = 0.25 : dropout ratio for context vector\n",
        "        \"\"\"\n",
        "        \n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.token_size = token_size\n",
        "\n",
        "        self.embedding_subtoken = nn.Embedding(input_size_subtoken, token_size, padding_idx=PAD)\n",
        "        self.embedding_node = nn.Embedding(input_size_node, token_size, padding_idx=PAD)\n",
        "        \n",
        "        self.lstm = nn.LSTM(token_size, token_size, bidirectional=True, dropout=rnn_dropout)\n",
        "        self.out = nn.Linear(token_size * 4, hidden_size)\n",
        "        \n",
        "        self.dropout = nn.Dropout(embeddings_dropout)\n",
        "\n",
        "    def forward(self, batch_S, batch_N, batch_E, lengths_k, index_N, hidden=None):\n",
        "        \n",
        "        \"\"\"\n",
        "        batch_S : (B * k, l) start terminals' subtoken of each ast path\n",
        "        batch_N : (l, B*k) nonterminals' nodes of each ast path\n",
        "        batch_E : (B * k, l) end terminals' subtoken of each ast path\n",
        "        \n",
        "        lengths_k : length of k in each example\n",
        "        index_N : index for unsorting,\n",
        "        \"\"\"\n",
        "        \n",
        "        output_bag = []\n",
        "        hidden_batch = []\n",
        "        \n",
        "        \n",
        "        # (B * k, l, d)\n",
        "        encode_S = self.embedding_subtoken(batch_S)\n",
        "        encode_E = self.embedding_subtoken(batch_E)\n",
        "        \n",
        "        \n",
        "        # encode_S (B * k, d) token_representation of each ast path\n",
        "        encode_S = encode_S.sum(1)\n",
        "        encode_E = encode_E.sum(1)\n",
        "        \n",
        "        #print('encode_S', encode_S)\n",
        "        #print('encode_E', encode_E)\n",
        "        \n",
        "        \n",
        "        # emb_N :(l, B*k, d)\n",
        "        \n",
        "        emb_N = self.embedding_node(batch_N)\n",
        "        packed = pack_padded_sequence(emb_N, lengths_N)\n",
        "        output, _ = self.lstm(packed, hidden)\n",
        "        output, _ = pad_packed_sequence(output)\n",
        "        \n",
        "        # output of shape (seq_len, B * k, num_directions * d)\n",
        "        # -> (B * k, seq_len, num_directions * d)\n",
        "        output = output.transpose(0, 1)\n",
        "        \n",
        "        #For the unpacked case, the directions can be separated using \n",
        "        # output.view(seq_len, batch, num_directions, hidden_size), \n",
        "        # with forward and backward being direction 0 and 1 respectively.\n",
        "        # -> (B * k, seq_len, num_directions,  d)\n",
        "        output = output.view(batch_N.shape[1], batch_N.shape[0], 2, self.token_size)\n",
        "        \n",
        "        \n",
        "        \n",
        "        #a b c d e\n",
        "        #f g h 0 0\n",
        "        #i j 0 0 0\n",
        "        #k 0 0 0 0\n",
        "        # output_normal should be [e, h, j, k] \n",
        "        # output_reverse          [a, f, i, k]\n",
        "        \n",
        "        ln = [lengths_N[0] * i + (l - 1) for i,l in enumerate(lengths_N)]\n",
        "        output_normal = output[:, :,  0, :]\n",
        "        output_normal = output_normal.contiguous().view(-1, self.token_size)\n",
        "        output_normal = output_normal[ln]\n",
        "        \n",
        "        output_reverse = output[:,  0,  1, :].view(batch_N.shape[1], self.token_size)\n",
        "        \n",
        "        # encode_N  :(B*k, 2d)\n",
        "        encode_N = torch.cat([output_normal, output_reverse], dim=1)\n",
        "        \n",
        "        # encode_SNE  : (B*k, 4d)\n",
        "        encode_SNE = torch.cat([encode_N, encode_S, encode_E], dim=1)\n",
        "        \n",
        "        # encode_SNE  : (B*k, d)\n",
        "        encode_SNE = self.out(encode_SNE)\n",
        "        \n",
        "        # unsort as example\n",
        "        index = torch.tensor(index_N, dtype=torch.long, device=device)\n",
        "        encode_SNE = torch.index_select(encode_SNE, dim=0, index=index)\n",
        "        \n",
        "        # as is in  https://github.com/tech-srl/code2seq/blob/ec0ae309efba815a6ee8af88301479888b20daa9/model.py#L511\n",
        "        encode_SNE = self.dropout(encode_SNE)\n",
        "        \n",
        "        # output_bag  : [ B, (k, d) ]\n",
        "        output_bag = torch.split(encode_SNE, lengths_k, dim=0)\n",
        "        # hidden_0  : [ B, (d) ]\n",
        "        hidden_0 = [ob.mean(0).unsqueeze(dim=0) for ob in output_bag]\n",
        "\n",
        "        # hidden_0  : (1, B, d)\n",
        "        # size should be like (1, batch_size, hidden_size)\n",
        "        hidden_0 = torch.cat(hidden_0, dim=0).unsqueeze(dim=0)\n",
        "        \n",
        "        return output_bag, hidden_0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "flU2AatIwrPl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, rnn_dropout):\n",
        "        \"\"\"\n",
        "        hidden_size : decoder unit size, \n",
        "        output_size : decoder output size, \n",
        "        rnn_dropout : dropout ratio for rnn\n",
        "        \"\"\"\n",
        "        \n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, dropout=rnn_dropout)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, seqs, hidden):\n",
        "        \n",
        "        emb = self.embedding(seqs)\n",
        "        output, hidden = self.gru(emb, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "XCPLR4MkQ_U1"
      },
      "cell_type": "markdown",
      "source": [
        "#### memo. Attention and its score function\n",
        "\n",
        "In this imprementation, score function is:\n",
        "$$\n",
        "   \\mathrm{score}(\\bar{h}_s, h_t) = h_t^{\\mathrm{T}} W_a \\bar{h}_s .\n",
        "$$\n",
        "\n",
        "The weight is\n",
        "$$\n",
        "    a_t(s) = \\frac{\\exp(\\mathrm{score}(\\bar{h}_s, h_t))}{\\sum^S_{s'=1}\\exp(\\mathrm{score}(\\bar{h}_s, h_t))} .\n",
        "$$\n",
        "\n",
        "And so on...\n",
        "$$\n",
        "    c_t = \\sum^S_{s=1} a_t(s) \\bar{h}_s\n",
        "$$\n",
        "$$\n",
        "    \\tilde{h}_t = \\tanh(W_h h_t + W_c c_t + b)\n",
        "$$\n",
        "$$\n",
        "    y_t = \\mathrm{softmax}(W_{out}\\tilde{h}_t + b_{out})\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zsuAuSteQ_U3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class EncoderDecoder_with_Attention(nn.Module):\n",
        "    \n",
        "    \"\"\"Conbine Encoder and Decoder\"\"\"\n",
        "    \n",
        "    def __init__(self, input_size_subtoken, input_size_node, token_size, output_size, hidden_size, rnn_dropout = 0.5, embeddings_dropout = 0.25):\n",
        "\n",
        "        super(EncoderDecoder_with_Attention, self).__init__()\n",
        "        self.encoder = Encoder(input_size_subtoken, input_size_node, token_size, hidden_size, rnn_dropout, embeddings_dropout)\n",
        "        self.decoder = Decoder(hidden_size, output_size, rnn_dropout)\n",
        "        \n",
        "        self.W_a  = torch.rand((hidden_size, hidden_size), dtype=torch.float,device=device , requires_grad=True)\n",
        "        self.W_cc = torch.rand((hidden_size, hidden_size), dtype=torch.float,device=device , requires_grad=True)\n",
        "        self.W_ch = torch.rand((hidden_size, hidden_size), dtype=torch.float,device=device , requires_grad=True)\n",
        "        self.b    = torch.rand(hidden_size, dtype=torch.float, device=device, requires_grad=True)\n",
        "        \n",
        "        nn.init.xavier_uniform_(self.W_a)\n",
        "        nn.init.xavier_uniform_(self.W_cc)\n",
        "        nn.init.xavier_uniform_(self.W_ch)\n",
        "        \n",
        "        \n",
        "\n",
        "    def forward(self, batch_S, batch_N, batch_E, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S, max_length_N,max_length_E,max_length_Y, lengths_k, index_N, terget_max_length, batch_Y=None, use_teacher_forcing=False):\n",
        "\n",
        "        # Encoder\n",
        "        encoder_output_bag, encoder_hidden = \\\n",
        "        self.encoder(batch_S, batch_N, batch_E, lengths_k, index_N)\n",
        "        _batch_size = len(encoder_output_bag)\n",
        "        \n",
        "        # calc initial decoder state with attention\n",
        "        decoder_hidden = self.attention(encoder_output_bag, encoder_hidden, lengths_k)\n",
        "        \n",
        "        # make initial input for decoder\n",
        "        decoder_input = torch.tensor([BOS] * _batch_size, dtype=torch.long, device=device)\n",
        "        decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n",
        "        \n",
        "        # output holder\n",
        "        decoder_outputs = torch.zeros(terget_max_length, _batch_size, self.decoder.output_size, device=device)\n",
        "        \n",
        "        for t in range(terget_max_length):\n",
        "            \n",
        "            # Decoder\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "            \n",
        "            # calc next hidden state w/ attention\n",
        "            decoder_hidden = self.attention(encoder_output_bag, decoder_hidden, lengths_k)\n",
        "            \n",
        "            # hold output\n",
        "            decoder_outputs[t] = decoder_output\n",
        "            \n",
        "            # Teacher Forcing\n",
        "            if use_teacher_forcing and batch_Y is not None:\n",
        "                decoder_input = batch_Y[t].unsqueeze(0)\n",
        "            else: \n",
        "                decoder_input = decoder_output.max(-1)[1]\n",
        "        \n",
        "        return decoder_outputs\n",
        "    \n",
        "    def attention(self, encoder_output_bag, hidden, lengths_k):\n",
        "        \n",
        "        \"\"\"\n",
        "        encoder_output_bag : (batch * k, hidden_size) bag of embedded ast path\n",
        "        hidden : (batch, hidden_size)  previous hidden state\n",
        "        lengths_k : (batch, 1) length of k in each example\n",
        "        \"\"\"\n",
        "        \n",
        "        # d_hidden:(1, sample, hidden_size) -> (sample, hidden_size)\n",
        "        d_hidden = hidden.squeeze(0)\n",
        "        \n",
        "        # d_hidden:(sample, hidden_size) \n",
        "        # -> (sample * k, hidden_size)\n",
        "        \n",
        "        index = torch.cat([ torch.tensor([i] * k, dtype=torch.long, device=device) for i,k in enumerate(lengths_k) ], dim =0)\n",
        "        d_hidden = torch.index_select(d_hidden, dim=0, index=index)\n",
        "        \n",
        "        # e_output : (sample * k, hidden_size)\n",
        "        e_output = torch.cat(encoder_output_bag, dim=0)\n",
        "        \n",
        "        # e_output: [sample * num_k(i), hidden_size(j)]\n",
        "        # self.W_a  : [hidden_size(j), hidden_size(k)]\n",
        "        # -> : [sample * num_k(i), hidden_size(k)]\n",
        "        score = einsum('ij,jk->ik', e_output, self.W_a)\n",
        "        \n",
        "        # d_hidden: [sample * k(i), hidden_size(j)]\n",
        "        # score:    [sample * k(i), hidden_size(j)]\n",
        "        # -> score: [sample * k(i), 1]\n",
        "        \n",
        "        score = torch.einsum('ij,ij->i', d_hidden, score).unsqueeze(1)\n",
        "        \n",
        "        # score: [sample * k(i), 1]\n",
        "        # -> [sample, k, 1]\n",
        "        score = torch.split(score, lengths_k, dim=0)\n",
        "        \n",
        "        #  attn_weights: [sample, k, 1]\n",
        "        attn_weights = [F.softmax(s, dim=0) for s in score]\n",
        "        \n",
        "        # aw: [k(i), 1(j)]\n",
        "        # eo: [k(i), hidden_size(k)]\n",
        "        # -> [1(j), hidden_size(k)]\n",
        "        context_vector = [torch.einsum('ij,ik->jk', aw, eo) for aw, eo in zip(attn_weights, encoder_output_bag)]\n",
        "        context_vector = torch.cat(context_vector, dim=0)\n",
        "        \n",
        "        # context_vector : (sample(i), hidden_size(j))\n",
        "        # self.W_cc : (hidden_size(j), hidden_size(k))\n",
        "        # -> (sample(i), hidden_size(k))\n",
        "        \n",
        "        # hidden : (1(i), sample(j), hidden_size(k))\n",
        "        # self.W_ch : (hidden_size(k), hidden_size(l))\n",
        "        # -> (sample(j), hidden_size(l))\n",
        "        \n",
        "        # decoder_hidden : (sample, hidden_size)\n",
        "        decoder_hidden = F.tanh(torch.einsum('ij,jk->ik', context_vector, self.W_cc) + \n",
        "                                torch.einsum('ijk,kl->jl', hidden, self.W_ch) + \n",
        "                                self.b)\n",
        "        \n",
        "        # decoder_hidden : (1, sample, hidden_size)\n",
        "        decoder_hidden = decoder_hidden.unsqueeze(0)\n",
        "        \n",
        "        return decoder_hidden\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YqnxqyXqwrP0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mce = nn.CrossEntropyLoss(size_average=False, ignore_index=PAD)\n",
        "def masked_cross_entropy(logits, target):\n",
        "    return mce(logits.view(-1, logits.size(-1)), target.view(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rOF5HCajwrP-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "# make dataloader instances\n",
        "#\n",
        "\n",
        "BATCH_SIZE = 512\n",
        "DEV_RATIO = 0.1\n",
        "NUM_K = 200\n",
        "\n",
        "SECTOR_SIZE = 10\n",
        "\n",
        "DATA_PATH_TRAIN = 'java-small/java-small.train.c2s'\n",
        "DATA_PATH_VALID = 'java-small/java-small.test.c2s'\n",
        "\n",
        "train_loader_param = {\n",
        "    'data_path' : DATA_PATH_TRAIN,\n",
        "    'num_examples' : num_length_train,\n",
        "    'batch_size' : BATCH_SIZE,\n",
        "    'num_k' : NUM_K,\n",
        "    'vocab_subtoken' : vocab_subtoken,\n",
        "    'vocab_nodes' : vocab_nodes,\n",
        "    'vocab_target' : vocab_target,\n",
        "    'sector_size' : SECTOR_SIZE\n",
        "}\n",
        "\n",
        "# $ wc -l java-small.test.c2s\n",
        "# 57088 java-small.test.c2s\n",
        "\n",
        "valid_loader_param = {\n",
        "    'data_path' : DATA_PATH_VALID,\n",
        "    'num_examples' : 57088,\n",
        "    'batch_size' : BATCH_SIZE,\n",
        "    'num_k' : NUM_K,\n",
        "    'vocab_subtoken' : vocab_subtoken,\n",
        "    'vocab_nodes' : vocab_nodes,\n",
        "    'vocab_target' : vocab_target,\n",
        "    'sector_size' : SECTOR_SIZE\n",
        "}\n",
        "\n",
        "train_dataloader = DataLoader(**train_loader_param)\n",
        "valid_dataloader = DataLoader(**valid_loader_param)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7kp7px_O7-1J",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "# make instances of optimizer and model\n",
        "#\n",
        "\n",
        "NUM_EPOCHS = 30\n",
        "\n",
        "INITIAL_RL = 0.01\n",
        "WEIGHT_DECAY = 0.01\n",
        "MOMENTUM = 0.95\n",
        "NESTEROV = True\n",
        "\n",
        "DECAY_RATIO = 0.95\n",
        "\n",
        "RNN_DROPOUT = 0.5\n",
        "EMBEDDING_DROPOUT = 0.25\n",
        "\n",
        "TOKEN_SIZE = 128\n",
        "HIDDEN_SIZE = 320\n",
        "\n",
        "model_args = {\n",
        "    'input_size_subtoken' : vocab_size_subtoken,\n",
        "    'input_size_node' : vocab_size_nodes,\n",
        "    'output_size' : vocab_size_target,\n",
        "    'hidden_size' : HIDDEN_SIZE, \n",
        "    'token_size' : TOKEN_SIZE,\n",
        "    'rnn_dropout' : RNN_DROPOUT, \n",
        "    'embeddings_dropout' : EMBEDDING_DROPOUT\n",
        "}\n",
        "\n",
        "model = EncoderDecoder_with_Attention(**model_args).to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=INITIAL_RL, weight_decay=WEIGHT_DECAY, momentum=MOMENTUM, nesterov = NESTEROV)\n",
        "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: DECAY_RATIO ** epoch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IujU0wrrwrQE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_loss(batch_S, batch_N, batch_E, batch_Y, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N, model, optimizer=None, is_train=True):\n",
        "    \n",
        "    # predict, calc loss and backward.\n",
        "    \n",
        "    model.train(is_train)\n",
        "    \n",
        "    use_teacher_forcing = is_train and (random.random() < teacher_forcing_rate)\n",
        "    \n",
        "    \n",
        "    target_max_length = batch_Y.size(0)\n",
        "    pred_Y = model(batch_S, batch_N, batch_E, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N, target_max_length, batch_Y, use_teacher_forcing)\n",
        "    \n",
        "    loss = masked_cross_entropy(pred_Y.contiguous(), batch_Y.contiguous())\n",
        "    \n",
        "    if is_train:\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    batch_Y = batch_Y.transpose(0, 1).contiguous().data.cpu().tolist()\n",
        "    pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().T.tolist()\n",
        "    \n",
        "    \n",
        "    return loss.item(), batch_Y, pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b_u0_eYjwrQM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calc_bleu(refs, hyps):\n",
        "    _refs = [[ref[:ref.index(EOS)]] for ref in refs]\n",
        "    _hyps = [hyp[:hyp.index(EOS)] if EOS in hyp else hyp for hyp in hyps]\n",
        "    \n",
        "    return 100 * bleu_score.corpus_bleu(_refs, _hyps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VSGeOxSqQ_VL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculate_results(refs, preds):\n",
        "    #calc precision, recall and F1\n",
        "    #same as https://github.com/tech-srl/code2seq/blob/ec0ae309efba815a6ee8af88301479888b20daa9/model.py#L239\n",
        "    \n",
        "    filterd_refs = [ref[:ref.index(EOS)] for ref in refs]\n",
        "    filterd_preds = [pred[:pred.index(EOS)] if EOS in pred else pred for pred in preds]\n",
        "    \n",
        "    true_positive, false_positive, false_negative = 0, 0, 0\n",
        "\n",
        "    for filterd_pred, filterd_ref in zip(filterd_preds, filterd_refs):\n",
        "\n",
        "        if filterd_pred == filterd_ref:\n",
        "            true_positive += len(filterd_pred)\n",
        "            continue\n",
        "\n",
        "        for fp in filterd_pred:\n",
        "            if fp in filterd_ref:\n",
        "                true_positive += 1\n",
        "            else:\n",
        "                false_positive += 1\n",
        "\n",
        "        for fr in filterd_ref:\n",
        "            if not fr in filterd_pred:\n",
        "                false_negative += 1\n",
        "\n",
        "    if true_positive + false_positive > 0:\n",
        "        precision = true_positive / (true_positive + false_positive) \n",
        "    else:\n",
        "        precision = 0\n",
        "\n",
        "    if true_positive + false_negative > 0:\n",
        "        recall = true_positive / (true_positive + false_negative)\n",
        "    else:\n",
        "        recall = 0\n",
        "\n",
        "    if precision + recall > 0:\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "    else:\n",
        "        f1 = 0\n",
        "    \n",
        "    return precision, recall, f1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nTCOrAinwrQQ",
        "scrolled": false,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#\n",
        "# Training Loop\n",
        "# \n",
        "\n",
        "teacher_forcing_rate = 0.2\n",
        "save_path = 'model.pth'\n",
        "best_valid_f1 = 0.\n",
        "\n",
        "# at first several iters, the score is unstable and would be not good for saving.\n",
        "# Model is saved after \"start_saving_epoch\"\n",
        "start_saving_epoch = 2\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(NUM_EPOCHS), desc='EPOCH'):\n",
        "    train_loss = 0.\n",
        "    train_refs = []\n",
        "    train_hyps = []\n",
        "    valid_loss = 0.\n",
        "    valid_refs = []\n",
        "    valid_hyps = []\n",
        "    \n",
        "    # train\n",
        "    for batch in tqdm(train_dataloader, total=train_dataloader.num_examples // train_dataloader.batch_size , desc='TRAIN'):\n",
        "        batch_S, batch_N, batch_E, batch_Y, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N = batch\n",
        "        \n",
        "        loss, gold, pred = compute_loss(\n",
        "            batch_S, batch_N, batch_E, batch_Y, \n",
        "            lengths_S, lengths_N, lengths_E, lengths_Y, \n",
        "            max_length_S,max_length_N,max_length_E,max_length_Y, \n",
        "            lengths_k, index_N, model, optimizer,\n",
        "            is_train=True\n",
        "            )\n",
        "        train_loss += loss\n",
        "        train_refs += gold\n",
        "        train_hyps += pred\n",
        "    \n",
        "    # valid\n",
        "    for batch in tqdm(valid_dataloader, total=valid_dataloader.num_examples // valid_dataloader.batch_size , desc='VALID'):\n",
        "\n",
        "        batch_S, batch_N, batch_E, batch_Y, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N = batch\n",
        "\n",
        "        loss, gold, pred = compute_loss(\n",
        "            batch_S, batch_N, batch_E, batch_Y, \n",
        "            lengths_S, lengths_N, lengths_E, lengths_Y, \n",
        "            max_length_S,max_length_N,max_length_E,max_length_Y, \n",
        "            lengths_k, index_N, model, optimizer,\n",
        "            is_train=False\n",
        "            )\n",
        "        valid_loss += loss\n",
        "        valid_refs += gold\n",
        "        valid_hyps += pred\n",
        "            \n",
        "\n",
        "    train_loss = np.sum(train_loss) / train_dataloader.num_examples\n",
        "    valid_loss = np.sum(valid_loss) / valid_dataloader.num_examples\n",
        "    \n",
        "    # BLEU\n",
        "    train_bleu = calc_bleu(train_refs, train_hyps)\n",
        "    valid_bleu = calc_bleu(valid_refs, valid_hyps)\n",
        "    \n",
        "    # F1 etc\n",
        "    train_precision, train_recall, train_f1 = calculate_results(train_refs, train_hyps)\n",
        "    valid_precision, valid_recall, valid_f1 = calculate_results(valid_refs, valid_hyps)\n",
        "\n",
        "    \n",
        "    #if valid_bleu > best_valid_bleu:\n",
        "    if valid_f1 > best_valid_f1 and epoch > start_saving_epoch:\n",
        "        tlpt = model.state_dict()\n",
        "        torch.save(tlpt, save_path)\n",
        "        best_valid_f1 = valid_f1\n",
        "        print('Best valid F1, model saved.')\n",
        "    \n",
        "    print('Epoch {}: train_loss: {:5.2f}  train_bleu: {:2.4f}  train_f1: {:2.4f}  valid_loss: {:5.2f}  valid_bleu: {:2.4f}  valid_f1: {:2.4f}'.format(\n",
        "            epoch, train_loss, train_bleu, train_f1, valid_loss, valid_bleu, valid_f1))\n",
        "    \n",
        "    print('-- Prediction example --')\n",
        "    for i, (ref, pred) in enumerate(zip(valid_refs[:5], valid_hyps[:5])):\n",
        "        print(i, 'REF  :',ids_to_sentence(vocab_target, trim_eos(ref)))\n",
        "        print(i, 'PRED :',ids_to_sentence(vocab_target, trim_eos(pred)))\n",
        "        print('-'*80)\n",
        "    \n",
        "    print('-'*80)\n",
        "    \n",
        "    scheduler.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QsQay14VEwYJ"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "swYlOn13Q_VU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load best model\n",
        "tlpt = torch.load(save_path)\n",
        "model.load_state_dict(tlpt)\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IkDZr9oEQ_VV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del train_dataloader, valid_dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2GKrKzSDQ_VW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#$ wc -l java-small.val.c2s\n",
        "#23844 java-small.val.c2s\n",
        "\n",
        "test_loader_param = {\n",
        "    'data_path' : 'java-small/java-small.val.c2s',\n",
        "    'num_examples' : 23844,\n",
        "    'batch_size' : 1,\n",
        "    'num_k' : 200,\n",
        "    'vocab_subtoken' : vocab_subtoken,\n",
        "    'vocab_nodes' : vocab_nodes,\n",
        "    'vocab_target' : vocab_target,\n",
        "    'sector_size' : 1\n",
        "}\n",
        "\n",
        "test_dataloader = DataLoader(**test_loader_param)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lY6ty-rNG76n",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "refs_list = []\n",
        "hyp_list = []\n",
        "\n",
        "for batch in tqdm(test_dataloader,\n",
        "                      total=test_dataloader.num_examples // test_dataloader.batch_size,\n",
        "                      desc='TEST'):\n",
        "    \n",
        "    batch_S, batch_N, batch_E, batch_Y, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N = batch\n",
        "    target_max_length = batch_Y.size(0)\n",
        "    use_teacher_forcing = False\n",
        "    \n",
        "    pred_Y = model(batch_S, batch_N, batch_E, lengths_S, lengths_N, lengths_E, lengths_Y, max_length_S,max_length_N,max_length_E,max_length_Y, lengths_k, index_N, target_max_length, batch_Y, use_teacher_forcing)\n",
        "    \n",
        "    refs = batch_Y.transpose(0, 1).contiguous().data.cpu().tolist()[0]\n",
        "    pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().T.tolist()[0]\n",
        "    \n",
        "    refs_list.append(refs)\n",
        "    hyp_list.append(pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VVDf6TOAPE8z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('-- Prediction example --')\n",
        "for i, (ref, pred) in enumerate(zip(refs_list[:5], hyp_list[:5])):\n",
        "    print(i, 'REF  :',ids_to_sentence(vocab_target, trim_eos(ref)))\n",
        "    print(i, 'PRED :',ids_to_sentence(vocab_target, trim_eos(pred)))\n",
        "    print('-'*80)\n",
        "    \n",
        "test_precision, test_recall, test_f1 = calculate_results(refs_list, hyp_list)\n",
        "\n",
        "print('Precision :', test_precision)\n",
        "print('Recall :', test_recall)\n",
        "print('F1 : ', test_f1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}